# 提示链模式
> 本文译自 [Agentic Design Patterns/Chapter 1: Prompt Chaining](https://github.com/wangwii/Agentic-Design-Patterns/blob/main/01-Part_One/Chapter_1-Prompt_Chaining-1flxKGrbnF2g8yh3F-oVD5Xx7ZumId56HbFpIiPdkqLI.md)

## 1.概览
提示链是一种利用大语言模型（LLMs)处理复杂任务的有效方式，有时也被称为管道模式。
该模式的核心是“分而治之”策略——即将原本复杂的问题分解成一系列更小、更易于管理的子问题，再针对每个子问题精心设计提示词，并将前一个问题的输出作为下一步任务的输入，从而形成“链式”依赖。

这种按顺序处理（子问题）的技术，将“模块化”和“清晰性”引入了与大语言模型（LLMs)交互的过程中， 通过拆解复杂的任务，让每个单独的步骤变的更易于理解、更稳健。
（针对子问题）序列中的每个步骤都可以精心设计和优化（提示词），（实现）聚焦于原问题的特定方面，从而获得更准确、更聚焦的输出。
（其中前）一步的输出作为下一步的输入至关重要，因为这种信息传递建立了“依赖链”，（形成了）先前操作的上下文和处理结果指导后续处理（的效果），这使得大语言模型（LLM）能够在其先前工作的基础上、完善其理解并逐步接近（用户）期望的解决方案。
而且，提示链模式不仅仅是分解问题，它还能整合外部的知识和工具，在每个（子问题的）处理步骤中，大语言模型（LLM）都可以按指令与外部系统、APIs 或数据库进行交互，从而超越其内部训练数据以外的知识和能力。这种能力极大地扩展了 LLM 的潜力，使其不仅能作为独立的模型发挥作用，还能成为更广泛、更智能系统的组成部分。

提示链范式的意义超越了简单的解决问题，而是构建复杂 AI 智能体的基础技术。这些智能体可以利用提示链模式在动态环境中自主规划、推理和行动。通过策略性的构建提示序列，智能体可以执行需要多步骤推理、规划和决策的任务。这样智能体的工作流程可以更紧密地模拟人类的思维过程，从而实现与复杂领域和系统更自然、更有效的交互。

**单一提示词的局限性：** 对于多层面的任务，使用单个复杂的 LLM 提示词会效率很低，并导致模型难以应对约束和指令，从而引起：“指令忽视（即部分提示丢失）”、“上下文漂移（即模型失去对出生上下文的追踪）”、“错误传播（即早期错误被放大）”、“提示需要更大的上下文窗口（即模型无法获得足够的信息来做出回应）”，以及“幻觉（即认知负荷增加了错误信息的概率）”。


例如，一个要求分析市场调研报告、总结调研结果、利用数据识别趋势以及起草一封电子邮件的任务可能会失败，因为模型可能总结得很好，但却无法提取数据，或不能正确起草电子邮件。


**(按逻辑)顺序的(提示词)分解提升可靠性：** 提示链通过将复杂任务分解为一个更聚焦的、按顺序逻辑的工作流程来应对（单一提示词的局限性）挑战，并显著提高了可靠性和可控性。

继续拿以上任务为例，采用管道模式或提示链方法的详细描述如下：
1. 初始提示词（摘要）：“总结一下市场报告的主要发现：[(市场报告内容)文本]。” 该步骤的唯一关注点是“总结”，从而提高初始步骤的准确性。
2. 第二提示词（趋势识别）：“使用摘要，识别3个新兴的主要趋势，并提取支持每个趋势的具体数据点：[步骤1的输出]。” 该提示受到更多限制且直接构建于经过验证的输出。
3. 第三提示词（撰写邮件）：“给市场营销团队起草一封简洁的电子邮件，概述以下趋势及其支持数据：[步骤2的输出]。” 

这种分步骤拆解允许对（处理）过程进行更精细的控制。每个步骤更简单并更为明确，这会减少 AI模型的认知负担并带来更准确和可靠的最终输出。
这种模块化类似计算流水线，其中每个（处理节点/）函数执行（简单/明确的）特定操作并将其处理结果传递给下一个（处理节点/函数）。
这种方法还可以为不同阶段（特定任务的处理模型）分配不同的角色，已获得更准确的响应。例如：在以上示例场景中，“初始提示词（摘要）”阶段可指定（角色）为“市场分析师”；“第二提示词（趋势识别）”阶段指定角色为“交易分析师”；“第三提示词（撰写邮件）”阶段指定（角色）为“专业文档撰写人”，依此类推。
